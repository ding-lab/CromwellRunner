#!/bin/bash

# Matthew Wyczalkowski <m.wyczalkowski@wustl.edu>
# https://dinglab.wustl.edu/

read -r -d '' USAGE <<'EOF'
Register, query, and archive Cromwell run output

Usage:
  bash runtidy [options] [RUN_NAME1 [ RUN_NAME2 ... ]]

Required options:

Optional options
-h: print usage information
-d: dry run: print commands but do not run
-v: verbose
-1: stop after one case processed.
-0: do not process any cases, exit after initialization
-x TASK: Execute given task.  Values: 'query' (default), 'register', 'stash', 'finalize'
-k RUN_LIST: file with list of all run names, one per line, used when RUN_NAME1 not defined. Default: dat/RUN_LIST.dat
-g LOGD: directory where runtime output (RUN_NAME.out, RUN_NAME.err, RUN_NAME.log ) can be found.  Default "./logs"
-T STASHD: root directory where we write archived logs.  Default "./logs/stashed"
-L RUNLOG: Run log file. Default is "./logs/runlog.dat".  Has to exist unless -f is set.  Can be obtained from environment variable
-f: Create run log file if it does not exist
-y YAMLD: directory with YAML input files (named RUN_NAME.yaml).  Default "./yaml"
-Y: move (not copy) YAML files
-F EXPECTED_STATUS: Define expected status of runs
-c CQD: explicit path to cromwell query utility `cq` and `datatidy`
-m NOTE: A note added to run log file for each case
-D DATATIDY_ARGS: arguments passed to datatidy during registration
-p PROJECT: Project name associated with this analysis, mandatory for register and finalize tasks

Runtidy performs the following task:
* `query`: Evaluate and print for each case
    - case, workflowId, path to run log 
* `register`: write entry in run log and register with `runtidy`
* `stash`: move run output files and copy YAML config file to directory named after workflowID
* `finalize`: Run `register` and `stash` 

Cromwell generates two classes of output 
* Data output in workflowRoot directory. See `datatidy` for details 
* Run output files (RUN_NAME.*) in LOGD directory, consisting of Cromwell stdout and stderr
  (possibly log file generated by GNU `parallel`). 
`runtidy` is concerned with the run output files, which are used to obtain a WorkflowID for a given run.  

Stashing a run consists of moving the run output files (and possibly YAML file)
to a directory STASHD/WorkflowID.  This is done to clean output directory and
allow for multiple runs for one case (e.g. to restart failed run).Stashing or
finalizing a run twice will print a warning.  If this WorkflowID does not exist
in runlog file exit with an error, since not having this entry will make it
hard to map RUN_NAME to WorkflowID in future.  Stashing also copies or moves YAML
files to stash directory; if status is Succeeded the YAML is moved, copied
otherwise (-Y to always move YAML files).

Registering a run creates an entry in run log file; this file tracks which case
is associated with which Workflow ID.  Runs are stashed only when
they have completed execution, but can be registered any time any number of times.

A run log (RUNLOG) file has the following columns
    * `Case`
    * `Project` (new)
    * `WorkflowID`
    * `Status`
    * `StartTime`
    * `EndTime`
    * `Note` - optional, may indicate whether a restart, etc.

Finalizing involves registering with run log file, stashing, and also
registering data output using `datatidy`.  This requires a project name 

By default, only runs with status (as obtained from `cq`) of `Succeeded` or
`Failed` are evaluated for `stash` and `finalize` tasks.  To stash and finalize
runs with some other status, EXPECTED_STATUS must be defined; then, all cases
must have a status (as obtained from `cq`) same as EXPECTED_STATUS. (This is to
help prevent inadvertant data loss from stashing running jobs)

All runs regardless of status are processed for `register` and `query` tasks.

If RUN_NAME is - then read RUN_NAME from STDIN.  If RUN_NAME is not defined, read from first column of RUN_LIST file.
`runtidy` script does not WorkflowIDs as arguments to define runs

This script relies on `cq` to get WorkflowID and status associated with each case

RUNLOG can be defined as environment variable, e.g., `export RUNLOG=/path/to/logs/runlog.dat`
EOF

source src/cromwell_utils.sh

SCRIPT=$(basename $0)
SCRIPT_PATH=$(dirname $0)

TASK="query"
LOGD="./logs"       # where we find Cromwell run logs
STASHD="./logs/stashed"     # where we put stashed logs
CQD="./src"

YAMLD="./yaml"
RUN_LIST="dat/RUN_LIST.dat"
QUIET=1

# read default from environment variable if possible, otherwise use default
if [ -z $RUNLOG ]; then
    RUNLOG="./logs/runlog.dat"
fi

while getopts ":hdv10x:k:g:T:L:y:YF:c:m:D:fp:" opt; do
  case $opt in
    h) 
      echo "$USAGE"
      exit 0
      ;;
    d)  # propagate to datatidy
      DRYRUN="d"
      QUIET=0   # print stuff out
      DATATIDY_ARGS="$DATATIDY_ARGS -d"
      ;;
    0)  
      JUSTZERO=1
      ;;
    1)  # propagate to datatidy
      JUSTONE=1
      DATATIDY_ARGS="$DATATIDY_ARGS -1"
      ;;
    v) 
      QUIET=0
      ;;
    x)
      TASK="$OPTARG"
      ;;
    k) 
      RUN_LIST="$OPTARG"
      ;;
    g) 
      LOGD="$OPTARG"
      ;;
    T) 
      STASHD="$OPTARG"
      ;;
    L) 
      RUNLOG="$OPTARG"
      ;;
    y) 
      YAMLD="$OPTARG"
      ;;
    Y) 
      YAML_MV=1
      ;;
    F) 
      EXPECTED_STATUS="$OPTARG"
      ;;
    c) 
      CQD="$OPTARG"
      ;;
    m)
      NOTE="$OPTARG"
      ;;
    D) 
      DATATIDY_ARGS="$DATATIDY_ARGS $OPTARG"
      ;;
    f) 
      MAKE_RUNLOG=1
      ;;
    p) 
      PROJECT="$OPTARG"
      ;;
    \?)
      >&2 echo "Invalid option: -$OPTARG" 
      >&2 echo "$USAGE"
      exit 1
      ;;
    :)
      >&2 echo "Option -$OPTARG requires an argument." 
      >&2 echo "$USAGE"
      exit 1
      ;;
  esac
done
shift $((OPTIND-1))

if [ -z $CQD ]; then
    CQ="bash cq"
    DATATIDY="bash datatidy"
else
    CQ="bash $CQD/cq"
    DATATIDY="bash $CQD/datatidy"
fi

# note about adding new tasks or modifying existing ones:
# rungo calls runtidy -q query to make sure things are working ok
if [ $TASK == "register" ] || [ $TASK == "finalize" ]; then
    # Confirm that PROJECT is defined.  
    if [ -z $PROJECT ]; then
        >&2 echo $SCRIPT ERROR: project \(-p\) is not defined.
        exit 1
    fi
fi

# this allows us to get case names in one of three ways:
# 1: cq RUN_NAME1 RUN_NAME2 ...
# 2: cat RUN_LIST.dat | cq -
# 3: read from RUN_LIST file
# Note that if no cases defined, assume RUN_NAME='-'
if [ "$#" == 0 ]; then
    confirm $RUN_LIST
    RUNS=$(cat $RUN_LIST | cut -f 1 )
elif [ "$1" == "-" ] ; then
    RUNS=$(cat - )
else
    RUNS="$@"
fi

# Test to make sure no cases look like UUIDs

for RUN_NAME in $RUNS; do
    if [[ $RUN_NAME =~ ^\{?[A-F0-9a-f]{8}-[A-F0-9a-f]{4}-[A-F0-9a-f]{4}-[A-F0-9a-f]{4}-[A-F0-9a-f]{12}\}?$ ]]; then
        >&2 echo ERROR: Case $RUN_NAME looks like a UUID
        exit 1
    fi
done

if [ ! -f $RUNLOG ]; then
    if [ -z $MAKE_RUNLOG ]; then
        >&2 echo $SCRIPT ERROR: RUNLOG file $RUNLOG does not exist, will not create one by default
        >&2 echo "        runlog file can be created with \`$SCRIPT -f1\`"
        exit 1
    fi
    >&2 echo Creating new run log $RUNLOG
    TARGET_DIR=$(dirname $RUNLOG)
    CMD=$(mkdir -p $TARGET_DIR)
    run_cmd $CMD "$DRYRUN" 1
    # Write header
    CMD="printf \"# Case\tProject\tWorkflowID\tStatus\tStartTime\tEndTime\tNote\n\" > $RUNLOG"
    run_cmd "$CMD" "$DRYRUN" 1
fi

function do_query {
    RUN_NAME=$1
# * `query`: Evaluate and print for each case
#     - case, workflowId, path to run log 
# TODO: add time start and duration of run
    WID=$( $CQ -V -q wid $RUN_NAME )
    printf "$RUN_NAME\t$WID\t$RUNLOG\n"
}

function do_register {
    RUN_NAME=$1

    STATUS=$( $CQ -V -q status $RUN_NAME )

    # CQL has all columns except for project and note
    CQL=$( $CQ -q runlog $RUN_NAME ) 
    test_exit_status $SCRIPT
    WID=$( echo "$CQL" | cut -f 2 )
    if [ "$WID" == "Unknown" ] || [ "$WID" == "Unassigned" ]; then
        continue
    fi

    CQLP=$(echo "$CQL" | awk -v p="$PROJECT" 'BEGIN{FS="\t";OFS="\t"}{print $1,p,$2,$3,$4,$5}')

    RL=$( printf "$CQL\t$NOTE\n" )

    if [ "$DRYRUN" ]; then
        >&2 echo Dryrun: runlog = "$RL"
    else
        echo "$RL" >> $RUNLOG
    fi
}

# Stashing detail. For each case:
#  * Test if RUN_NAME.err, RUN_NAME.out, and RUN_NAME.yaml files exist.  
#    If any do not, test to see if stashed directory (based on WorkflowID) exists.
#    If it does not, print warning and continue to next case
#  * Obtain WorkflowID of case based on RUN_NAME.out.
#  * Obtain Status of WorkflowID based on call to `cq`
#    * if Status is not "Succeeded" print warning and continue to next case, unless FORCE_STATUS=1
#  * Check if STASHD/WorkflowID directory exists.  If it does, exit with an error
#  * Check if runlog has entry with WorkflowID.  If it does not, exit with an error
#  * Move LOGD/RUN_NAME.* to STASHD/WorkflowID
#  * If STATUS = Succeeded or YAML_MV is defined
#    * Move YAMLD/RUN_NAME.yaml to STASHD/WorkflowID
#    * otherwise copy YAMLD/RUN_NAME.yaml to STASHD/WorkflowID
function do_stash {
    RUN_NAME=$1

    OUTFN="$LOGD/$RUN_NAME.out"
    ERRFN="$LOGD/$RUN_NAME.err"
    YAMLFN="$YAMLD/$RUN_NAME.yaml"
    WID=$( $CQ -V -q wid $RUN_NAME ) 

    if [ ! -f $OUTFN ] || [ ! -f $ERRFN ] || [ ! -f $YAMLFN ]; then
    # Log files missing.  See if they've already been stashed
        echo NOTE: Missing files: $OUTFN  $ERRFN  $YAMLFN
        if [ -d $LOGD/$WID ]; then
            >&2 echo $RUN_NAME already stashed 
        else
            >&2 echo WARNING: $RUN_NAME: Log/yaml files do not exist, not stashing
            >&2 echo $LOGD/$WID does not exist
        fi
        return
    fi

    # WID may be unknown for various reasons, like error conditions.  Stashing requires that this
    # value be known; if it is not, print a complaint and go on
    if [ $WID == "Unknown" ]; then
        >&2 echo WARNING: WorkflowID for $RUN_NAME is $WID.  Not stashing these logs, continuing
        return
    fi

    STATUS=$( $CQ -V -q status $RUN_NAME ) 
    test_exit_status $SCRIPT
    if [ $STATUS == "Succeeded" ] || [ "$YAML_MV" ]; then
        YAML_CMD="mv"
    else
        YAML_CMD="cp"
    fi

    if ! grep -F -q $WID $RUNLOG ; then
        if [ ! "$DRYRUN" ]; then
            >&2 echo $SCRIPT ERROR: $RUN_NAME \( $WID \) not found in $RUNLOG. Register run with \`runLogger.sh\` before stashing
            exit 1
        fi
    fi

    OUTD="$STASHD/$WID"
    if [ -d $OUTD ]; then
        >&2 echo WARNING: Stash directory exists: $OUTD
        >&2 echo Skipping this case
        return
    fi

    CMD="mkdir -p $OUTD"
    run_cmd "$CMD" "$DRYRUN" $QUIET 

    #CMD="mv $LOGD/$RUN_NAME.* $OUTD"
    CMD="mv $LOGD/${RUN_NAME}.err $LOGD/${RUN_NAME}.out $LOGD/${RUN_NAME}.LSF.err $LOGD/${RUN_NAME}.LSF.out $OUTD"
    run_cmd "$CMD" "$DRYRUN" $QUIET

    CMD="$YAML_CMD $YAMLD/$RUN_NAME.yaml $OUTD"
    run_cmd "$CMD" "$DRYRUN" $QUIET
}

# if expecting a given status, first pre-check to make sure all cases are of this status
# to do this.  Note this is alternative logic to datatidy, where testing during main loop
if [ ! -z $EXPECTED_STATUS ]; then
    DOCKET=""
    >&2 echo Testing docket
    for RUN_NAME in $RUNS; do
        STATUS=$( $CQ -V -q status $RUN_NAME )
        if [ "$STATUS" != "$EXPECTED_STATUS" ]; then
            >&2 echo $SCRIPT ERROR: Status of case $RUN_NAME \( $STATUS \) differs from expected \( $EXPECTED_STATUS \)
            exit 2  # to distinguish status mismatch from garden variety errors
        fi
        DOCKET="$DOCKET $RUN_NAME"
        if [ $JUSTONE ]; then
            break
        fi
    done
    RUN_NAME=$DOCKET    #  RUN_NAME replenished to loop through all cases again
fi

CMD="mkdir -p $LOGD"
run_cmd "$CMD" "$DRYRUN"

# -0 may be called to create runlog file then exit without processing any cases
if [ $JUSTZERO ]; then
    exit 0
fi

for RUN_NAME in $RUNS; do

    STATUS=$( $CQ -V -q status $RUN_NAME )
    test_exit_status $SCRIPT
    case "$TASK" in
      "query")
        do_query $RUN_NAME  
        ;;
      "register")
        do_register $RUN_NAME 
        ;;
      "stash")
        if [ -z $EXPECTED_STATUS ]; then
            if [ "$STATUS" != "Succeeded" ] && [ "$STATUS" != "Failed" ]; then
                >&2 echo Skipping $RUN_NAME \(Status $STATUS not Succeeded or Failed.  Specify expected status with -F to stash\)
                continue
            fi
        fi
        do_stash $RUN_NAME 
        ;;
      "finalize")
        DATATIDY_ARGS="$DATATIDY_ARGS -p $PROJECT"   
        if [ -z $EXPECTED_STATUS ]; then
            if [ "$STATUS" != "Succeeded" ] && [ "$STATUS" != "Failed" ]; then
                >&2 echo Skipping $RUN_NAME \(Status $STATUS not Succeeded or Failed.  Specify expected status with -F to finalize\)
                continue
            fi
        else
            # If expected status is defined, pass this along to datatidy.  
            DATATIDY_ARGS="$DATATIDY_ARGS -F $EXPECTED_STATUS "   
        fi
        if [ ! -z "$NOTE" ]; then   # NOTE can have spaces, so escaping it is a pain
            $DATATIDY -m "$NOTE" $DATATIDY_ARGS -x original $RUN_NAME 
        else
            $DATATIDY $DATATIDY_ARGS -x original $RUN_NAME 
        fi
        test_exit_status $SCRIPT
        do_register $RUN_NAME 
        do_stash $RUN_NAME
        ;;
      *)
        >&2 echo $SCRIPT ERROR: Unknown task $TASK
        >&2 echo "$USAGE"
        exit 1
        ;;
    esac

    if [ $JUSTONE ]; then
        break
    fi

done

