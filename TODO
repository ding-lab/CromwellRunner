# Notes for future development

* Have an automated way of saving parameters associated with runs, e.g., database versions and such when
  reporting and staging results.
  These are specified in YAML files and PARAMS files.  However, not all variables specified in PARAMS
  are relevant (SomaticSV may not use all variables, which were defined for TinDaisy)
  Perhaps could extract common lines in YAML files?  (and avoid BAMs)?

* use WUdocker for starting image.  Should not run everything in an interactive docker container like step 00, but rather
  start runs within a non-interactive job, like done in step 25 here:
    https://github.com/ding-lab/importGDC.CPTAC3.git
  the reason for this is that compute1 has a 24-hour limit on interactive jobs

* whole datatidy / runtidy log stuff is maddening.  Default instructions don't work.  Make this simple for the case of running first time


# Previous notes
Implement basic non-db functionality (so that datatidy can be used)
Improve error handling if database does not exist / is down / is not correctly defined
Update documentation with description of local database
Think through where runlog and datalog files go.  Currently in ./logs, probably not the best place
Allow prune step to use arbitrary configuration file to define which files kept

Have a sense of "batches" or "generations" of runs.  Currently, when some runs fail, even after they're finalized, 
    `cq` will report that they are still failed.  This is confusing if they are being re-run.  Having an idea of 
    batches, or recognizing that a run has been finalized, will be helpful.
    One idea is to report in `cq` output whether runs have been finalized


Do a sanity check in runtidy to see if a UUID was passed instead of a case name
exit with an error if so

get from VLD_FilterVCF/src/start_docker.sh
    https://github.com/ding-lab/VLD_FilterVCF

